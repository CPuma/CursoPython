{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas es un paquete de Python que proporciona estructuras de datos __rápidas, flexibles y expresivas__ diseñadas para que trabajar con datos __\"relacionales\" o \"etiquetados\"__ sea fácil e intuitivo, es una de las librerias más usadas debido a su potencia y además es de código abierto . Su función es ser una herramienta de alto nivel para realizar__ analisis de datos__ en el mundo real. \n",
    "\n",
    "Pandas es muy adecuado para muchos tipos diferentes de datos:\n",
    "\n",
    "- Datos tabulares con columnas de tipo heterogéneo, como en una tabla de SQL o una hoja de cálculo de Excel\n",
    "- Datos de series de tiempo ordenados y no ordenados (no necesariamente de frecuencia fija).\n",
    "- Datos de matriz arbitraria (homogéneamente tipados o heterogéneos) con etiquetas de fila y columna\n",
    "- Cualquier otra forma de conjuntos de datos observacionales / estadísticos. Los datos realmente no necesitan ser etiquetados en absoluto para ser colocados en una estructura de datos pandas.\n",
    "\n",
    "Pandas ofrece las siguientes estructuras de datos:\n",
    "\n",
    "* __Series__: Son arrays unidimensionales con indexación (arrays con índice o etiquetados), similar a los diccionarios. Pueden generarse a partir de diccionarios o de listas.\n",
    " \n",
    "* __DataFrame__: Son estructuras de datos similares a las tablas de bases de datos relacionales como SQL.\n",
    " \n",
    "* __Panel, Panel4D y PanelND__: Estas estructuras de datos permiten trabajar con más de dos dimensiones. Dado que es algo complejo y poco utilizado trabajar con arrays de más de dos dimensiones no trataremos los paneles en estos tutoriales de introdución a Pandas.\n",
    "\n",
    "Aquí están algunas de las cosas que los pandas hacen bien:\n",
    "\n",
    "- Manejo fácil de __datos faltantes__ (representados como __NaN__) en punto flotante así como datos de punto no flotante.\n",
    "- Cambios de tamaño: las columnas se pueden __insertar y eliminar__ de DataFrame y objetos de dimensiones superiores.\n",
    "- __Alineación automática y explícita de datos__: los objetos pueden alinearse explícitamente con un conjunto de etiquetas, o el usuario puede simplemente ignorar las etiquetas y dejar que Series, DataFrame, etc. alineen automáticamente los datos en cálculos.\n",
    "- Potente y flexible al __agrupar por funcionalidad__ para realizar operaciones __split-apply-combine__ en conjuntos de datos, tanto para la agregación como para la transformación de datos.\n",
    "- __Facilita la conversión__ de datos desiguales y diferenciados en otras estructuras de datos Python y NumPy en objetos DataFrame.\n",
    "- Recorte inteligente basado en __slicing, fancy indexing, y subsetting__ de grandes conjuntos de datos.\n",
    "- Robustas herramientas de IO para cargar datos de __archivos planos__ (CSV y delimitado), archivos de Excel, bases de datos y guardar / cargar datos desde el formato __HDF5 ultrarrápido__.\n",
    "- __Funciones específicas de series de tiempo__: generación de intervalos de fechas y conversión de frecuencia, estadísticas de ventanas en movimiento, regresiones lineales de ventanas en movimiento, cambio de fecha y retraso, etc.\n",
    "\n",
    "Para los científicos de datos, el trabajo con datos suele dividirse en múltiples etapas: muestrear y limpiar los datos, analizarlos o modelarlos, y luego organizar los resultados del análisis en una forma adecuada para representación gráfica o tabular. Pandas es la herramienta ideal para todas estas tareas.\n",
    "\n",
    "Otras notas:\n",
    "\n",
    "- Pandas es __rápido__. Muchos de los bits algorítmicos de bajo nivel se han modificado extensamente en el código de Cython. Sin embargo, como con cualquier otra cosa, la generalización suele sacrificar el rendimiento. Así que si usted se centra en una característica para su aplicación que puede ser capaz de crear una herramienta especializada más rápida.\n",
    "- Pandas es una dependencia de __statsmodels__, por lo que es una parte importante del ecosistema de computación estadística en Python.\n",
    "- Pandas ha sido ampliamente utilizado en la producción en __aplicaciones financieras__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora empecemos importando pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forma convencional de importar pandas:\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando matplotlib para graficar \n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructuras de Datos\n",
    "------------------------------\n",
    "\n",
    "### Series\n",
    "\n",
    "La estructura de datos de Series en Pandas es una matriz etiquetada unidimensional.\n",
    "\n",
    "- Los datos de la matriz pueden ser de cualquier tipo (números enteros, cadenas, números de punto flotante, objetos Python, etc.).\n",
    "\n",
    "- Los datos dentro de la matriz son homogéneos.\n",
    "\n",
    "- Los datos pueden ser listas, arrays, o un diccionario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    33\n",
       "1    19\n",
       "2    15\n",
       "3    89\n",
       "4    11\n",
       "5    -5\n",
       "6     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructor de serie con datos como una lista de enteros\n",
    "s1 = pd.Series([33, 19, 15, 89, 11, -5, 9])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo de serie es la serie pandas\n",
    "type(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33, 19, 15, 89, 11, -5,  9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recupera los valores de la serie \n",
    "s1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo de valores de datos es NumPy ndarray\n",
    "type(s1.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](../images/series.jpg \"Optional title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mon    33\n",
       "Tue    19\n",
       "Wed    15\n",
       "Thu    89\n",
       "Fri    11\n",
       "Sat    -5\n",
       "Sun     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define los datos e indices como listas\n",
    "data1 = [33, 19, 15, 89, 11, -5, 9]\n",
    "index1 = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "\n",
    "# Crea la serie \n",
    "s2 = pd.Series(data1, index=index1)\n",
    "\n",
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Alt text](../images/series2.jpg \"Optional title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday\n",
       "Mon    33\n",
       "Tue    19\n",
       "Wed    15\n",
       "Thu    89\n",
       "Fri    11\n",
       "Sat    -5\n",
       "Sun     9\n",
       "Name: Daily Temperatures, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# También podemos dar etiquetas significativas a los datos de la serie y el índice\n",
    "\n",
    "s2.name='Daily Temperatures'\n",
    "s2.index.name='Weekday'\n",
    "\n",
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La representación más general de una serie es como un almacén de key-values ordenado.\n",
    "\n",
    "- El orden es representado por el offset.\n",
    "- El valor-clave es una asignación de índice o etiqueta a los valores de matriz de datos.\n",
    "- Indice como \"offset\" o \"posición\" vs índice como \"etiqueta\" o \"clave\".\n",
    "\n",
    "![Alt text](../images/series3.jpg \"Optional title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser las series de tipo__NumPy-ndarray__ podemos efectuar las mismas operaciones que hicimos en Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday\n",
       "Mon     66\n",
       "Tue     38\n",
       "Wed     30\n",
       "Thu    178\n",
       "Fri     22\n",
       "Sat    -10\n",
       "Sun     18\n",
       "Name: Daily Temperatures, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday\n",
       "Mon    33\n",
       "Tue    19\n",
       "Wed    15\n",
       "Name: Daily Temperatures, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos usar el slicing usando la posicion\n",
    "s2[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday\n",
       "Mon    33\n",
       "Tue    19\n",
       "Wed    15\n",
       "Name: Daily Temperatures, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tambien podemos usar slicin usando sus etiquetas(labes)\n",
    "s2['Mon':'Wed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniendo Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrs</th>\n",
       "      <th>bathrs</th>\n",
       "      <th>price_sqr_meter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrs  bathrs  price_sqr_meter\n",
       "0      1       2            19510\n",
       "1      2       1            15190\n",
       "2      1       2            16107\n",
       "3      1       1            22991\n",
       "4      2       2            24508"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "s1 = pd.Series(np.random.randint(1, high=5, size=100, dtype='l'))\n",
    "s2 = pd.Series(np.random.randint(1, high=4, size=100, dtype='l'))\n",
    "s3 = pd.Series(np.random.randint(10000, high=30001, size=100, dtype='l'))\n",
    "\n",
    "housemkt = pd.concat([s1, s2, s3], axis=1)\n",
    "housemkt.rename(columns = {0: 'bedrs', 1: 'bathrs', 2: 'price_sqr_meter'}, inplace=True)\n",
    "\n",
    "housemkt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n",
    "\n",
    "La estructura de datos de DataFrame en Pandas es una matriz etiquetada bidimensional.\n",
    "\n",
    "- Los datos de la matriz pueden ser de cualquier tipo (números enteros, cadenas, números de punto flotante, objetos Python, etc.).\n",
    "- Los datos dentro de cada columna son homogéneos\n",
    "- De forma predeterminada, Pandas crea un índice numérico para las filas en la secuencia 0 ... n\n",
    "\n",
    "![Alt text](../images/dataframe.jpg \"Optional title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Creamos una lista de fechas desde 12-01 to 12-10\n",
    "dt = datetime.datetime(2016,12,1)\n",
    "end = datetime.datetime(2016,12,10)\n",
    "step = datetime.timedelta(days=1)\n",
    "dates = []\n",
    "\n",
    "# Rellenar la lista\n",
    "while dt < end:\n",
    "    dates.append(dt.strftime('%m-%d'))\n",
    "    dt += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12-01',\n",
       " '12-02',\n",
       " '12-03',\n",
       " '12-04',\n",
       " '12-05',\n",
       " '12-06',\n",
       " '12-07',\n",
       " '12-08',\n",
       " '12-09']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arequipa</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lima</th>\n",
       "      <th>Puno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>12-01</td>\n",
       "      <td>20</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>12-02</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>12-03</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>12-04</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>12-05</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>12-06</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>12-07</td>\n",
       "      <td>23</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>12-08</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>12-09</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Arequipa   Date  Lima  Puno\n",
       "0        15  12-01    20    -2\n",
       "1        19  12-02    18     0\n",
       "2        15  12-03    23     2\n",
       "3        11  12-04    19     5\n",
       "4         9  12-05    25     7\n",
       "5         8  12-06    27    -5\n",
       "6        13  12-07    23    -3\n",
       "7        14  12-08    29     4\n",
       "8        16  12-09    30     7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Date': dates, 'Arequipa' : [15,19,15,11,9,8,13,14,16], 'Puno': [-2,0,2,5,7,-5,-3,4,7], 'Lima':[20,18,23,19,25,27,23,29,30]}\n",
    "temps = pd.DataFrame(d)\n",
    "temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leyendo data de un archivo csv \n",
    "\n",
    "Puede leer datos de un archivo __CSV__ (comma-separated values) utilizando la función read_csv. \n",
    "\n",
    "Vamos a buscar algunos datos de avistamientos de ovnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leyendo el dataset de reportes de avistamientos en un dataframe\n",
    "ufo = pd.read_csv('../data/ufo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Colors Reported</th>\n",
       "      <th>Shape Reported</th>\n",
       "      <th>State</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ithaca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRIANGLE</td>\n",
       "      <td>NY</td>\n",
       "      <td>6/1/1930 22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Willingboro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NJ</td>\n",
       "      <td>6/30/1930 20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Holyoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>CO</td>\n",
       "      <td>2/15/1931 14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISK</td>\n",
       "      <td>KS</td>\n",
       "      <td>6/1/1931 13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York Worlds Fair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>NY</td>\n",
       "      <td>4/18/1933 19:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City Colors Reported Shape Reported State             Time\n",
       "0                Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
       "1           Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
       "2               Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
       "3               Abilene             NaN           DISK    KS   6/1/1931 13:00\n",
       "4  New York Worlds Fair             NaN          LIGHT    NY  4/18/1933 19:00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examinamos las 5 primeras filas\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentacion de [read_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos leer data de una web, en este caso leeremos un archivo __TSV__ (Tabular-separated-values): con __read_table__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leyendo el dataset de ordenes de Chipotle de una URL y guardar los resultados en un dataframe\n",
    "orders = pd.read_table('http://bit.ly/chiporders')\n",
    "\n",
    "#mostramos las ultimas filas\n",
    "orders.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar una Columna o __\"Serie\"__ usamos la notacion []:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ufo['City'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien podemos usar la notación punto (__.__):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.City.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La notacion de brackets [] o corchetes siempre funciona mientras que la notación del punto tiene limitaciones:\n",
    "\n",
    "- La notación de puntos no funciona si hay espacios en el nombre de la serie\n",
    "- La notación de puntos no funciona si la Serie tiene el mismo nombre que un método o atributo de DataFrame (como 'head' o 'shape')\n",
    "- No se puede utilizar la notación de puntos para definir el nombre de una nueva serie (véase más adelante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leyendo un dataset de las top-rated IMDb movies en un dataframe\n",
    "\n",
    "movies = pd.read_csv('../data/imdb.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método describe: calcula un resumen de estadísticas\n",
    "\n",
    "movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porqué algunos comandos de pandas terminan en parentesis y otros no?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los __métodos__ terminan con paréntesis, mientras que los __atributos__ no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de atributo: obtener el data type de cada columna\n",
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilice un parámetro opcional para describir el método para resumir sólo las columnas 'object'\n",
    "movies.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a obtener el numero de peliculas por clasificación de contenido ( R, PG-13, PG.. etc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_ratings = movies['content_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinamos las 5 ultimas filas\n",
    "ufo = pd.read_csv('../data/ufo.csv')\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los nombres de cada columna deben de tratar de no tener espacios, para ello podemos cambiar el nombre de las columnas de distintas formas como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar todos los nombres de columnas sobrescribiendo el atributo 'columnas'\n",
    "ufo_cols = ['city', 'colors_reported', 'shape_reported', 'state', 'time']\n",
    "ufo.columns = ufo_cols\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar dos de las columnas mediante el método 'rename'\n",
    "ufo.rename(columns={'colors_reported':'Colors_Reported_test', 'shape_reported':'Shape_Reported_test'}, inplace=True)\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para remover una columna usamos el método __drop__ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar una columna (axis=1 se refiere a columnas)\n",
    "ufo.drop('Colors_Reported_test', axis=1, inplace=True)\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar varias columnas a la vez\n",
    "ufo.drop(['state', 'time'], axis=1, inplace=True)\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar varias filas a la vez (axis=0 se refiere a filas)\n",
    "ufo.drop([0, 1], axis=0, inplace=True)\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering y Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examinamos las 5 primeras filas\n",
    "movies = pd.read_csv('../data/imdb.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si queremos ordenar usamos el metodo sort_values()\n",
    "\n",
    "movies.title.sort_values(ascending=False).head() # En este caso ordenamos de forma descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos: los indices se mantienen con cada fila cuando filtramos el dataframe\n",
    "movies[movies.content_rating=='PG-13'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar todo el DataFrame por la serie 'title' (devuelve un DataFrame)\n",
    "\n",
    "movies.sort_values('title').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objetivo:__ filtrar las filas de DataFrame para mostrar sólo películas con una \"duración\" de al menos 200 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_long = movies.duration >= 200\n",
    "movies[is_long]\n",
    "\n",
    "# O de forma equivalente, escríbalo en una línea (no es necesario crear el objeto 'is_long')\n",
    "\n",
    "movies[movies.duration >= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona la serie 'genre' del DataFrame filtrado\n",
    "movies[movies.duration >= 200].genre\n",
    "\n",
    "# O de forma equivalente, use el método 'loc'\n",
    "movies.loc[movies.duration >= 200, 'genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Meta:__ Filtrar aún más el DataFrame de películas largas (duration> = 200) para mostrar sólo películas que también tienen un 'genre' de 'Drama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[(movies.duration >=200) & (movies.genre == 'Drama')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objetivo:__ Filtrar el DataFrame original para mostrar películas con un 'genre' de 'Crime' o 'Drama' o 'Action' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza el '|' Operador para especificar que una fila puede coincidir con cualquiera de los tres criterios\n",
    "movies[(movies.genre == 'Crime') | (movies.genre == 'Drama') | (movies.genre == 'Action')].head(10)\n",
    "\n",
    "# O de forma equivalente, use el método 'isin'\n",
    "movies[movies.genre.isin(['Crime', 'Drama', 'Action'])].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el dataset de Chipotle orders en un DataFrame\n",
    "\n",
    "orders = pd.read_table('http://bit.ly/chiporders')\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convierte un string a un numero para poder hacer operaciones matemáticas\n",
    "\n",
    "orders.item_price.str.replace('$', '').astype(float).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método string 'contains' checkea si es que hay un substring que contenga 'Chicken' y retorna una serie booleana\n",
    "\n",
    "orders.item_name.str.contains('Chicken').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte una serie booleana a un entero (False = 0 , True = 1)\n",
    "\n",
    "orders.item_name.str.contains('Chicken').astype(int).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el dataset de consumo de alcohol en un dataframe\n",
    "\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la media de cervezas servidas solo en paises del continente africano\n",
    "\n",
    "drinks[drinks.continent=='Africa'].beer_servings.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la media de cervezas servidas por cada continente\n",
    "\n",
    "drinks.groupby('continent').beer_servings.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Especificando una columna a la que se debe aplicar la función de agregación no se requiere\n",
    "\n",
    "drinks.groupby('continent').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrama de barras de lado a lado del DataFrame de arriba\n",
    "\n",
    "drinks.groupby('continent').beer_servings.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of the 'value_counts' for the 'genre' Series\n",
    "movies.genre.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejando Valores perdidos o Missing Values\n",
    "\n",
    "¿Qué significa \"NaN\"? \n",
    "\n",
    "- \"NaN\" no es una cadena, sino que es un valor especial: __numpy.nan__. \n",
    "- Representa \"Not a number\" e indica un valor faltante. \n",
    "- __read_csv__ detecta los valores perdidos (de forma predeterminada) al leer el archivo y los reemplaza con este valor especial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leyendo el dataset de reportes de avistamientos en un dataframe\n",
    "ufo = pd.read_csv('../data/ufo.csv')\n",
    "ufo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si color reported es null retornara True\n",
    "ufo['Colors Reported'].isnull().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso contrario retornara False con notnull()\n",
    "ufo['Colors Reported'].notnull().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos devuelve el dataframe con las columnas vacias de City\n",
    "ufo[ufo.City.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve el numero de filas y columnas\n",
    "ufo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si faltan 'algun (any)' valor en una fila entonces elimina esa fila esa fila\n",
    "ufo.dropna(how='any').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si faltan todos(all) los valores en una fila, entonces elimina esa fila (no se eliminan en este caso)\n",
    "ufo.dropna(how='all').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si falta algun valor en una fila (teniendo en cuenta sólo 'City' y 'Shape Reported'), entonces se elimina esa fila\n",
    "ufo.dropna(subset=['City', 'Shape Reported'], how='any').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si \"all\" los valores estan faltantes en una filla (considerando solo 'City' y 'Shape Reported') entonces elimina esa fila\n",
    "ufo.dropna(subset=['City', 'Shape Reported'], how='all').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'value_counts' no incluye missing values por defecto\n",
    "ufo['Shape Reported'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluye explícitamente los missing values\n",
    "ufo['Shape Reported'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rellenar los valores faltantes con un valor especificado\n",
    "ufo['Shape Reported'].fillna(value='VARIOUS', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmar que los valores faltantes fueron rellenados\n",
    "ufo['Shape Reported'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing \n",
    "\n",
    "El método __loc__ se utiliza para seleccionar filas y columnas por etiqueta. Puede pasar\n",
    ": \n",
    "- Una etiqueta única \n",
    "- Una lista de etiquetas \n",
    "- Una porción de etiquetas  \n",
    "- Una serie booleana \n",
    "- Dos puntos (que indica \"todas las etiquetas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leyendo la data de crimen cometidos en los EEUU\n",
    "crime_data = pd.read_csv('../data/crime.csv')\n",
    "crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fila 0, todas las columnas\n",
    "crime_data.loc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filas 0 , 1 y 2, all columns\n",
    "crime_data.loc[[0, 1, 2], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filas 0 a la 8, all columns\n",
    "crime_data.loc[0:8 ,  :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filas 0 a la 3, all columns\n",
    "crime_data.loc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filas de la 0 a la 4 (incluyendo) las columnas 'State' y 'Count'\n",
    "crime_data.loc[0:4, ['State', 'Count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método __iloc__ se utiliza para seleccionar filas y columnas por posición entera. Se puede pasar: \n",
    "\n",
    "- Una sola posición entera \n",
    "- Una lista de posiciones enteras \n",
    "- Una porción de posiciones enteras \n",
    "- Dos puntos (que indica \"todas las posiciones enteras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filas en la posicion 0 al 2 (excluyente) todas las columnas\n",
    "crime_data.iloc[0:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método __ix__ se utiliza para seleccionar filas y columnas por etiqueta o posición de número entero, y sólo debe utilizarse cuando se necesita mezclar selección basada en etiquetas y enteros en la misma llamada.\n",
    "\n",
    "Reglas para el uso de números con ix: \n",
    "\n",
    "- Si el índice es cadenas, los números se tratan como posiciones enteras, y por lo tanto los cortes son exclusivos a la derecha. \n",
    "- Si el índice es números enteros, los números se tratan como etiquetas y, por lo tanto, los cortes son inclusivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el dataset de consumo de alcohol en un DataFrame y establecer 'país' como el índice\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry', index_col='country')\n",
    "drinks.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fila con la etiqueta 'Albania' columna en la posicion 0\n",
    "drinks.ix['Albania', 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fila en la posicion 1, columna con etiqueta 'beer_servings'\n",
    "drinks.ix[1, 'beer_servings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filas 'Albania' hasta 'Andorra' (inclusiva), columnas en la posicion 0 hasta 2 (exclusiva)\n",
    "drinks.ix['Albania':'Andorra', 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Entonces... ¿Cuáles son las diferencias entre loc, iloc, e ix? veamos... __\n",
    "\n",
    "Usemos la vieja confiable para contestar esta pregunta, es bueno buscar preguntas en internet ya que es imposible memorizar tantos metodos... ;) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/31593201/pandas-iloc-vs-ix-vs-loc-explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "Podemos aplicar funciones a data series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alcoholics(x):\n",
    "    if x > 10:\n",
    "        return 'alcoholics!'\n",
    "    else:\n",
    "        return 'Sober people'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks['Kind of people'] = drinks['total_litres_of_pure_alcohol'].apply(alcoholics)\n",
    "drinks.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de Dummy Variables\n",
    "\n",
    "En general: \n",
    "- Si tiene __\"K\" posibles valores__ para una característica categórica, sólo necesita __\"K-1\" dummy variables __ para capturar toda la información sobre esa característica. \n",
    "- Una convención es __eliminar la primera variable ficticia__, que define ese nivel como la \"baseline\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leyendo la data de crimen cometidos en los EEUU\n",
    "titanic = pd.read_csv('../data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the 'Sex_male' dummy variable using the 'map' method\n",
    "titanic['Sex_male'] = titanic.Sex.map({'female':0, 'male':1})\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(titanic.Sex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la primera first dummy variable ('female') usando el metodo iloc\n",
    "pd.get_dummies(titanic.Sex, prefix='Sex').iloc[:, 1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando 'get_dummies' Con una característica que tiene 3 valores posibles\n",
    "pd.get_dummies(titanic.Embarked, prefix='Embarked').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la primera dummy variable ('C')\n",
    "\n",
    "pd.get_dummies(titanic.Embarked, prefix='Embarked').iloc[:, 1:].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo traducir estos valores de nuevo al valor original __'Embarked'__:\n",
    "* 0, 0 significa C\n",
    "* 1, 0 significa Q\n",
    "* 0, 1 significa S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasa el DataFrame a 'get_dummies' y especifica qué columnas a dummy (descarta las columnas originales)\n",
    "\n",
    "titanic = pd.read_csv('../data/titanic.csv')\n",
    "pd.get_dummies(titanic, columns=['Sex', 'Embarked']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza el parámetro 'drop_first' (nuevo en pandas 0.18) para eliminar la primera variable dummy para cada característica\n",
    "\n",
    "pd.get_dummies(titanic, columns=['Sex', 'Embarked'], drop_first=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "¿Son los niños más altos que las niñas en promedio a los X años? X puede ser 2 años, 9 años y 18 años de edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niños = pd.read_csv('../data/children_heights.txt',sep='\\t')\n",
    "niños.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Resumen de estadísticas\n",
    "niños.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(df, columns):\n",
    "    df[columns].hist(color='r', alpha=0.3, normed=False)\n",
    "\n",
    "plot_hist(niños,['Boys_2', 'Girls_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(niños,['Boys_9', 'Girls_9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(niños, ['Boys_18', 'Girls_18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def plot_probs(df, boy_col, girl_col):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    # No considero los valores Nan\n",
    "    boy_values = df[boy_col].values\n",
    "    boy_values = boy_values[~np.isnan(boy_values)]\n",
    "    weights = np.ones_like(boy_values)/len(boy_values)\n",
    "    _ = ax.hist(boy_values, alpha=0.3, label=['Niños'], weights=weights)\n",
    "    girl_values = df[girl_col].values\n",
    "    girl_values = girl_values[~np.isnan(girl_values)]\n",
    "    weights = np.ones_like(girl_values)/len(girl_values)\n",
    "    _ = ax.hist(girl_values, color='red', alpha=.3, label='Niñas', weights=weights)\n",
    "    ax.set_xlabel('Altura(cm)', fontsize=14)\n",
    "    ax.set_ylabel('Probabilidad', fontsize=14)\n",
    "    ax.vlines(np.mean(boy_values), 0.0, ax.get_ylim()[1], colors='b', linestyle='--', linewidth=4)\n",
    "    ax.vlines(np.mean(girl_values), 0.0, ax.get_ylim()[1], colors='r', linestyle='--', linewidth=4)\n",
    "    ax.legend()\n",
    "    print(\"Resultado \", ttest_ind(boy_values, girl_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_probs(niños, 'Boys_2', 'Girls_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probs(niños, 'Boys_9', 'Girls_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probs(niños, 'Boys_18', 'Girls_18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese que aunque hay diferencias en las alturas de niñas y niños a los 2 años 9, no se encuentran diferencias significativas en promedio. Sin embargo, a los 18 años de edad, en promedio los niños son más altos que las niñas y esta diferencia es estadísticamente significativa a nivel de 0,05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leyendo el dataset de reportes de avistamientos en un dataframe\n",
    "ufo = pd.read_csv('../data/ufo.csv')\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hora se puede acceder usando el corte de cadena, pero este enfoque se rompe con demasiada facilidad\n",
    "ufo.Time.str.slice(-5, -3).astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte 'Time' a un datetime format\n",
    "ufo['Time'] = pd.to_datetime(ufo.Time)\n",
    "ufo['Time'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convertir una sola cadena al formato datetime (sale un objeto timestamp)\n",
    "\n",
    "ts = pd.to_datetime('1/1/1999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comparar una serie de fecha y hora con una marca de tiempo\n",
    "ufo.loc[ufo.Time >= ts, :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuenta el numero de avistamientos de ovnis por año\n",
    "\n",
    "ufo['Year'] = ufo.Time.dt.year\n",
    "ufo['Year'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica el número de informes de OVNI por año\n",
    "\n",
    "ufo.Year.value_counts().sort_index().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda da el estilo al notebook\n",
    "from IPython.core.display import HTML\n",
    "css_file = '../styles/StyleCursoPython.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
